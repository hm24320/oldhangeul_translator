# 중세-근대국어 분류 모델

## 1. 데이터 수집
'국어 역사 말뭉치' 다운('모두의 말뭉치', https://kli.korean.go.kr/corpus/main/requestMain.do)

## 2. 데이터 전처리 과정

### 2.1 텍스트 추출 (텍스트 추출.py)
**목적**: XML 파일에서 한국어 문장을 추출하고 연도별로 분류

**주요 기능**:
- XML 파일에서 `lang="kor"` 속성을 가진 `<sent>` 태그 내용 추출
- `<date>` 태그에서 연도 정보 추출 및 파싱
- 연도 기준으로 중세국어(900-1591년)와 근대국어(1592-1894년)로 분류
- 문장 그룹별로 개별 텍스트 파일로 저장 (`HXRW2320000XXX_partXXX.txt` 형식)

**처리 결과**:
- `Dataset/중세국어/` 폴더: 중세국어 텍스트 파일들
- `Dataset/근대국어/` 폴더: 근대국어 텍스트 파일들

### 2.2 텍스트 변환 (텍스트 변환.py)
**목적**: 한양 PUA(Private Use Area) 코드를 첫가끝 코드로 변환

**주요 기능**:
- `OldHangeul` 라이브러리의 `hNFD` 함수 사용
- Dataset 폴더 내 모든 `.txt` 파일에 대해 일괄 변환 처리
- 번호가 있는 문장의 경우 번호 부분은 보존하고 텍스트 부분만 변환
- 원본 파일을 덮어쓰기 방식으로 변환

**처리 대상**:
- `Dataset/근대국어/` 폴더의 모든 txt 파일
- `Dataset/중세국어/` 폴더의 모든 txt 파일

### 2.3 태그 삭제 (태그 삭제.py)
**목적**: 텍스트에서 불필요한 XML 태그 제거

**주요 기능**:
- `<add>〃</add>` 패턴의 태그를 정규표현식으로 삭제
- Dataset 폴더 내 모든 txt 파일을 재귀적으로 검색하여 처리
- 변경사항이 있는 파일만 업데이트

**처리 결과**:
- 깔끔한 텍스트 데이터 완성
- 분류 모델 학습을 위한 전처리 완료

## 3. 데이터 처리 파이프라인 요약

```
XML 파일 (NIKL 국어 역사 말뭉치)
    ↓
1. 텍스트 추출.py
    - XML 파싱 및 한국어 문장 추출
    - 연도별 분류 (중세국어/근대국어)
    - 개별 텍스트 파일로 저장
    ↓
2. 텍스트 변환.py
    - 한양 PUA → 첫가끝 코드 변환
    - OldHangeul 라이브러리 활용
    ↓
3. 태그 삭제.py
    - 불필요한 XML 태그 제거
    - 최종 텍스트 데이터 정리
    ↓
분류 모델 학습용 데이터셋 완성
```

## 4. 앞으로 해야 할 일
분류 모델 개발(python) - 중세국어와 근대국어를 자동으로 분류하는 인공지능 모델 개발